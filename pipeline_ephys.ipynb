{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebed39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spikeinterface.preprocessing import detect_bad_channels\n",
    "from spikeinterface_gui import run_mainwindow\n",
    "import spikeinterface.full as si\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "import pandas as pd\n",
    "from spikeinterface.exporters import export_to_phy\n",
    "from spikeinterface.curation import remove_duplicated_spikes, remove_redundant_units\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ef3df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streams: ['imec0.ap', 'nidq', 'imec0.lf', 'imec0.ap-SYNC', 'imec0.lf-SYNC']\n",
      "AP stream: imec0.ap\n",
      "SpikeGLXRecordingExtractor: 384 channels - 30000.505021 Hz - 1 segments - 170,689,039 samples \n",
      "                            5,689.54s (1.58 hours) - int16 dtype - 122.09 GiB\n",
      "AP Fs: 30000.505020920504 Hz | #ch: 384 | dur(s): 5689.539\n",
      "First 10 AP ch IDs: ['imec0.ap#AP0' 'imec0.ap#AP1' 'imec0.ap#AP2' 'imec0.ap#AP3'\n",
      " 'imec0.ap#AP4' 'imec0.ap#AP5' 'imec0.ap#AP6' 'imec0.ap#AP7'\n",
      " 'imec0.ap#AP8' 'imec0.ap#AP9']\n",
      "NIDQ stream: nidq\n",
      "SpikeGLXRecordingExtractor: 9 channels - 10593.500000 Hz - 1 segments - 60,272,088 samples \n",
      "                            5,689.53s (1.58 hours) - int16 dtype - 1.01 GiB\n",
      "NIDQ Fs: 10593.5 Hz | #ch: 9 | dur(s): 5689.535\n"
     ]
    }
   ],
   "source": [
    "# readdata\n",
    "# === Read SpikeGLX folder only (AP for spikes, NIDQ for TTL) ===\n",
    "\n",
    "SPIKEGLX_FOLDER = r\"E:/testephys\"  # spikeglx folder\n",
    "streams, _ = si.get_neo_streams('spikeglx', SPIKEGLX_FOLDER)\n",
    "print(\"streams:\", streams)\n",
    "AP_STREAM = next(n for n in streams if n.endswith(\".ap\"))\n",
    "print(\"AP stream:\", AP_STREAM)\n",
    "\n",
    "rec_ap = si.read_spikeglx(SPIKEGLX_FOLDER, stream_name=AP_STREAM, load_sync_channel=False)\n",
    "print(rec_ap)\n",
    "print(\"AP Fs:\", rec_ap.sampling_frequency, \"Hz | #ch:\", rec_ap.get_num_channels(),\n",
    "      \"| dur(s):\", round(rec_ap.get_total_duration(), 3))\n",
    "print(\"First 10 AP ch IDs:\", rec_ap.get_channel_ids()[:10])\n",
    "\n",
    "# NIDAQ for TTL\n",
    "NIDQ_STREAM = next((n for n in streams if \"nidq\" in n.lower()), None)\n",
    "if NIDQ_STREAM is None:\n",
    "    print(\"No NIDQ stream found.\")\n",
    "    rec_nidq = None\n",
    "else:\n",
    "    rec_nidq = si.read_spikeglx(SPIKEGLX_FOLDER, stream_name=NIDQ_STREAM)\n",
    "    print(\"NIDQ stream:\", NIDQ_STREAM)\n",
    "    print(rec_nidq)\n",
    "    print(\"NIDQ Fs:\", rec_nidq.sampling_frequency, \"Hz | #ch:\", rec_nidq.get_num_channels(),\n",
    "          \"| dur(s):\", round(rec_nidq.get_total_duration(), 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25467bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization Probe:\n",
    "probe = rec_ap.get_probe()\n",
    "df = probe.to_dataframe()\n",
    "display(df.head())\n",
    "print(\"列：\", list(df.columns))\n",
    "print(\"y范围 (µm):\", float(df[\"y\"].min()), \"→\", float(df[\"y\"].max()))\n",
    "print(\"通道数：\", rec_ap.get_num_channels())\n",
    "print(\"locations shape:\", rec_ap.get_channel_locations().shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 10))\n",
    "sw.plot_probe_map(rec_ap, ax=ax, with_channel_ids=True)\n",
    "ax.set_title(\"Probe map (AP stream from SpikeGLX)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#part of probe\n",
    "y0, y1 = -100, 100\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "sw.plot_probe_map(rec_ap, ax=ax, with_channel_ids=True)\n",
    "ax.set_ylim(y0, y1)\n",
    "ax.set_title(f\"Probe map zoomed: y ∈ [{y0},{y1}] µm\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7412edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied phase_shift (inter_sample_shift).\n",
      "Bad channels detected: ['imec0.ap#AP191']\n"
     ]
    }
   ],
   "source": [
    "# preprocessing: bandpass → phase_shift → remove bad channels → CAR\n",
    "def _has_prop_safe(recording, key: str) -> bool:\n",
    "    try:\n",
    "        return key in recording.get_property_keys()\n",
    "    except Exception:\n",
    "        try:\n",
    "            recording.get_property(key)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "rec_ap_bp = spre.bandpass_filter(rec_ap, freq_min=300, margin_ms=5.0)\n",
    "\n",
    "need_ps = _has_prop_safe(rec_ap_bp, \"inter_sample_shift\") or _has_prop_safe(rec_ap, \"inter_sample_shift\")\n",
    "if need_ps:\n",
    "    try:\n",
    "        rec_ap_ps = spre.phase_shift(rec_ap_bp)\n",
    "        print(\"Applied phase_shift (inter_sample_shift).\")\n",
    "    except Exception as e:\n",
    "        print(\"phase_shift skipped due to error:\", e)\n",
    "        rec_ap_ps = rec_ap_bp\n",
    "else:\n",
    "    rec_ap_ps = rec_ap_bp\n",
    "    print(\"No inter_sample_shift; skip phase_shift.\")\n",
    "\n",
    "bad_ids, ch_labels = detect_bad_channels(\n",
    "    recording=rec_ap_ps,\n",
    "    method='coherence+psd'  \n",
    ")\n",
    "if len(bad_ids):\n",
    "    print(\"Bad channels detected:\", bad_ids)\n",
    "    try:\n",
    "        rec_ap_ps_good = rec_ap_ps.remove_channels(bad_ids) \n",
    "    except Exception:\n",
    "        rec_ap_ps_good = rec_ap_ps\n",
    "        print(\"remove_channels() not available; skipped removal.\")\n",
    "else:\n",
    "    print(\"No bad channels detected.\")\n",
    "    rec_ap_ps_good = rec_ap_ps\n",
    "\n",
    "\n",
    "rec_ap_pre = spre.common_reference(rec_ap_ps_good, reference='global', operator='median')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efc6802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037881b48e74482d8e303b56c97b2206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 10 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c083d8dfc16c4ae39ee57623a53b2df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect and localize (workers: 10 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86e888276664100bb311fa916e92d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross correlation:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f251d72534547cd8b2687badfb7d44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solve:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# motion correction\n",
    "si.set_global_job_kwargs(n_jobs=10, chunk_duration=\"1s\", progress_bar=True)\n",
    "\n",
    "rec_ap_mc, motion_info = spre.correct_motion(\n",
    "    rec_ap_pre,\n",
    "    preset=\"dredge\",#\"dredge\"maybe better for NP\n",
    "    folder=Path(\"E:/testephys/motion\"),\n",
    "    output_motion_info=True,\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "si.plot_motion_info(\n",
    "    motion_info,\n",
    "    rec_ap_mc,                 \n",
    "    figure=fig,\n",
    "    depth_lim=None,\n",
    "    color_amplitude=True,\n",
    "    amplitude_cmap='inferno',\n",
    "    scatter_decimate=10,\n",
    ")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e1691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whitening (for sorting only)\n",
    "rec_ap_white = spre.whiten(rec_ap_mc,dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2ed304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kilosort4 params:\n",
      "{'Th_learned': 8,\n",
      " 'Th_single_ch': 6,\n",
      " 'Th_universal': 9,\n",
      " 'acg_threshold': 0.2,\n",
      " 'artifact_threshold': inf,\n",
      " 'bad_channels': None,\n",
      " 'batch_size': 20000,\n",
      " 'binning_depth': 5,\n",
      " 'ccg_threshold': 0.25,\n",
      " 'chunk_duration': '1s',\n",
      " 'clear_cache': True,\n",
      " 'cluster_downsampling': 10,\n",
      " 'cluster_neighbors': 10,\n",
      " 'delete_recording_dat': True,\n",
      " 'dmin': None,\n",
      " 'dminx': 32,\n",
      " 'do_CAR': False,\n",
      " 'do_correction': False,\n",
      " 'drift_smoothing': [0.5, 0.5, 0.5],\n",
      " 'duplicate_spike_ms': 0.25,\n",
      " 'fs': 30000,\n",
      " 'highpass_cutoff': 100.0,\n",
      " 'invert_sign': False,\n",
      " 'keep_good_only': False,\n",
      " 'max_channel_distance': 32,\n",
      " 'max_cluster_subset': None,\n",
      " 'max_peels': 100,\n",
      " 'max_threads_per_worker': 1,\n",
      " 'min_template_size': 10,\n",
      " 'mp_context': None,\n",
      " 'n_jobs': 10,\n",
      " 'n_pcs': 6,\n",
      " 'n_templates': 6,\n",
      " 'nblocks': 0,\n",
      " 'nearest_chans': 10,\n",
      " 'nearest_templates': 100,\n",
      " 'nskip': 25,\n",
      " 'nt': 61,\n",
      " 'nt0min': None,\n",
      " 'pool_engine': 'process',\n",
      " 'position_limit': 100,\n",
      " 'progress_bar': True,\n",
      " 'save_extra_vars': False,\n",
      " 'save_preprocessed_copy': False,\n",
      " 'scale': None,\n",
      " 'shift': None,\n",
      " 'sig_interp': 20,\n",
      " 'skip_kilosort_preprocessing': True,\n",
      " 'template_sizes': 5,\n",
      " 'templates_from_data': True,\n",
      " 'torch_device': 'auto',\n",
      " 'use_binary_file': True,\n",
      " 'whitening_range': 32,\n",
      " 'x_centers': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8535/8535 [1:08:06<00:00,  2.09it/s]\n",
      "100%|██████████| 2/2 [10:51<00:00, 325.99s/it]\n",
      "100%|██████████| 8535/8535 [57:23<00:00,  2.48it/s]  \n",
      "100%|██████████| 2/2 [11:38<00:00, 349.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kilosort4 done. #units = 1188\n"
     ]
    }
   ],
   "source": [
    "KS4_OUT = Path(r\"E:/testephys/sorting_ks4\")  # output folder for Kilosort4\n",
    "KS4_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ks4_params = ss.get_default_sorter_params('kilosort4')\n",
    "ks4_params.update(dict(\n",
    "    skip_kilosort_preprocessing=True,  \n",
    "    do_CAR=False,\n",
    "    highpass_cutoff=100.0,\n",
    "    nblocks=0, \n",
    "    do_correction=False,             \n",
    "    batch_size=20000,\n",
    "    use_binary_file=True,    \n",
    "    clear_cache=True,\n",
    "    max_cluster_subset = None,\n",
    "    cluster_downsampling = 10,       \n",
    "))\n",
    "print(\"Kilosort4 params:\")\n",
    "pprint(ks4_params)\n",
    "\n",
    "sorting = ss.run_sorter(\n",
    "    sorter_name='kilosort4',\n",
    "    recording=rec_ap_white,    \n",
    "    folder=KS4_OUT,\n",
    "    remove_existing_folder=True,\n",
    "    **ks4_params\n",
    ")\n",
    "print(\"Kilosort4 done. #units =\", len(sorting.unit_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d74def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823e7186fa534f0aa4c8f9f723a3c611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_sparsity (workers: 10 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c61ea599db494db88314670151fc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_templates_with_accumulator (workers: 10 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dedup] units: 1188 -> after spike-de-dup: 1188 -> after unit-de-dup:  1182\n"
     ]
    }
   ],
   "source": [
    "# prepostprocessing-remove duplicated spikes & redundant units\n",
    "rec_for_metrics = rec_ap_mc\n",
    "\n",
    "sorting_clean = remove_duplicated_spikes(sorting, censored_period_ms=0.20)\n",
    "tmp_an = si.create_sorting_analyzer(\n",
    "    sorting=sorting_clean,\n",
    "    recording=rec_for_metrics,      \n",
    "    format=\"memory\",\n",
    "    sparse=True,\n",
    ")\n",
    "\n",
    "tmp_an.compute(\"random_spikes\", save=False,\n",
    "               extension_params={\"random_spikes\": {\"method\": \"uniform\",\n",
    "                                                  \"max_spikes_per_unit\": 500,\n",
    "                                                  \"seed\": 0}})\n",
    "tmp_an.compute(\"templates\", save=False)\n",
    "tmp_an.compute(\"template_similarity\", save=False)\n",
    "tmp_an.compute(\"correlograms\", save=False,\n",
    "               extension_params={\"correlograms\": {\"window_ms\": 50.0, \"bin_ms\": 1.0}})\n",
    "\n",
    "sorting_dedup = remove_redundant_units(\n",
    "    tmp_an,\n",
    "    duplicate_threshold=0.90,\n",
    "    remove_strategy=\"minimum_shift\",\n",
    ")\n",
    "\n",
    "print(f\"[dedup] units: {len(sorting.unit_ids)} -> \"\n",
    "      f\"after spike-de-dup: {len(sorting_clean.unit_ids)} -> \"\n",
    "      f\"after unit-de-dup:  {len(sorting_dedup.unit_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ce5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.copy_metadata(sorting_dedup, ids=sorting_dedup.unit_ids)\n",
    "\n",
    "def normalize_str_props(S, keys=(\"group\",\"KSLabel\",\"quality\")):\n",
    "    for k in keys:\n",
    "        if k in S.get_property_keys():\n",
    "            v = np.asarray(S.get_property(k))\n",
    "            if v.dtype == object:\n",
    "                v = v.astype(str)\n",
    "            S.set_property(k, v.astype(\"U16\"))\n",
    "\n",
    "normalize_str_props(sorting_dedup, keys=(\"group\",\"KSLabel\",\"quality\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c128264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942c2433f19c4fcf89f2a1517cf143bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_sparsity (workers: 8 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer created. #units = 1182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deae06e47df9437e81b74e7c88137122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 8 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d010016f344b7db2c92cc4b988a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "compute_waveforms (workers: 8 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7cf3b5d69849e19f69b5b547e5bf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spike_amplitudes (no parallelization):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5afd3f4feb4c6eb7c695bf990f8415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting PCA:   0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15a8a935c5b4e2e883c43b6bd8052c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Projecting waveforms:   0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded extensions: ['noise_levels', 'random_spikes', 'waveforms', 'templates', 'spike_amplitudes', 'unit_locations', 'isi_histograms', 'principal_components', 'template_similarity', 'correlograms']\n"
     ]
    }
   ],
   "source": [
    "# postprocessing\n",
    "#rec_for_metrics = rec_ap_mc\n",
    "si.set_global_job_kwargs(n_jobs=8, chunk_duration=\"1s\", progress_bar=True)\n",
    "\n",
    "OUT = Path(r\"E:/testephys/postprocessing\")\n",
    "\n",
    "an = si.create_sorting_analyzer(\n",
    "    sorting=sorting_dedup,# sorting=sorting_dedup\n",
    "    recording=rec_for_metrics,\n",
    "    format=\"zarr\",\n",
    "    folder=OUT,\n",
    "    return_in_uV=False,\n",
    "    sparse=True,\n",
    "    method=\"radius\",           \n",
    "    radius_um=100.0,#default 40 for NP            \n",
    "    peak_sign=\"neg\",\n",
    "    num_spikes_for_sparsity=200,  \n",
    "    ms_before=1.5, ms_after=2.0    \n",
    ")\n",
    "print(\"Analyzer created. #units =\", len(an.unit_ids))\n",
    "\n",
    "an.compute(\"noise_levels\", save=True)\n",
    "\n",
    "an.compute(\n",
    "    \"random_spikes\",\n",
    "    save=True,\n",
    "    extension_params={\"random_spikes\": {\"method\": \"uniform\", \"max_spikes_per_unit\": 500, \"seed\": 0}},\n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"waveforms\",\n",
    "    save=True,\n",
    "    extension_params={\"waveforms\": {\"ms_before\": 1.5, \"ms_after\": 2.0, \"dtype\": \"int16\"}},#1.5/2.0 or 3.0/4.0 \n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"templates\",\n",
    "    save=True,\n",
    "    extension_params={\"templates\": {\"operators\": [\"average\", \"median\", \"std\"]}},\n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"spike_amplitudes\",\n",
    "    save=True,\n",
    "    n_jobs=1,  \n",
    "    extension_params={\"spike_amplitudes\": {\"peak_sign\": \"neg\"}},\n",
    ")\n",
    "\n",
    "\n",
    "an.compute(\n",
    "    \"unit_locations\",\n",
    "    save=True,\n",
    "    method=\"monopolar_triangulation\" \n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"isi_histograms\", \n",
    "    save=True\n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"principal_components\",\n",
    "    n_components=5, mode=\"by_channel_local\", whiten=True,\n",
    "           save=True, \n",
    "           n_jobs=1\n",
    ") \n",
    "\n",
    "an.compute(\n",
    "    \"template_similarity\", \n",
    "    save=True\n",
    ")\n",
    "\n",
    "an.compute(\n",
    "    \"correlograms\", \n",
    "    window_ms=50.0, bin_ms=1.0,\n",
    "    save=True,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "print(\"Loaded extensions:\", an.get_loaded_extension_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ffc449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\neuron\\envs\\torch\\Lib\\site-packages\\spikeinterface\\qualitymetrics\\misc_metrics.py:1066: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presence_ratio</th>\n",
       "      <th>amplitude_cutoff</th>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <th>isi_violations_count</th>\n",
       "      <th>snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>6.529590</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.138973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>2.942587</td>\n",
       "      <td>139.0</td>\n",
       "      <td>6.838252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.407232</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5.973751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.254358</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10.669648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.946015</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>10.198142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   presence_ratio  amplitude_cutoff  isi_violations_ratio  \\\n",
       "0        0.404255          0.000791              6.529590   \n",
       "1        0.446809          0.000433              2.942587   \n",
       "2        1.000000          0.000246              0.407232   \n",
       "3        1.000000          0.000356              0.254358   \n",
       "4        0.723404          0.000048              0.946015   \n",
       "\n",
       "   isi_violations_count        snr  \n",
       "0                  72.0   4.138973  \n",
       "1                 139.0   6.838252  \n",
       "2                 102.0   5.973751  \n",
       "3                  59.0  10.669648  \n",
       "4                1021.0  10.198142  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#pass QC(Allen-3) = 570 / 1182\n",
      "sorting_qc units: 570\n",
      "Saved: E:/testephys/quality_metrics.csv and E:/testephys/unit_ids_qc.csv\n"
     ]
    }
   ],
   "source": [
    "#quality metrics & QC (Allen-3)\n",
    "def _resolve_isi_col(df):\n",
    "    candidates = [\n",
    "        \"isi_violations_ratio\", \"isi_violation_ratio\", \"isi_violation_rate\",\n",
    "        \"isi_violation\", \"rp_contamination\"\n",
    "    ]\n",
    "    for k in candidates:\n",
    "        if k in df.columns:\n",
    "            return k\n",
    "    raise KeyError(f\"找不到 ISI 相关列，现有列：{list(df.columns)}\")\n",
    "\n",
    "metric_names = [\"presence_ratio\", \"amplitude_cutoff\", \"isi_violation\", \"snr\"]\n",
    "\n",
    "qm = si.compute_quality_metrics(\n",
    "    an,\n",
    "    metric_names=metric_names,\n",
    "    metric_params={\n",
    "        \"isi_violation\": {\"isi_threshold_ms\": 1.5, \"min_isi_ms\": 0.0},\n",
    "        \"snr\": {\"peak_sign\": \"neg\"}  \n",
    "    },\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    display(qm.head())\n",
    "except Exception:\n",
    "    print(qm.head())\n",
    "\n",
    "isi_key = _resolve_isi_col(qm)\n",
    "\n",
    "\n",
    "# Allen criteria\n",
    "PRESENCE_T = 0.90\n",
    "AMP_T = 0.10\n",
    "ISI_T = 0.50\n",
    "\n",
    "qc_mask = (\n",
    "    (qm[\"presence_ratio\"] > PRESENCE_T) &\n",
    "    (qm[\"amplitude_cutoff\"] < AMP_T) &\n",
    "    (qm[isi_key] < ISI_T)\n",
    ")\n",
    "qc_unit_ids = qm.index[qc_mask].tolist()\n",
    "print(f\"#pass QC(Allen-3) = {len(qc_unit_ids)} / {len(qm)}\")\n",
    "\n",
    "sorting_qc = sorting.select_units(qc_unit_ids)\n",
    "print(\"sorting_qc units:\", len(sorting_qc.unit_ids))\n",
    "\n",
    "qm_out_csv = r\"E:/testephys/quality_metrics.csv\"\n",
    "qc_list_csv = r\"E:/testephys/unit_ids_qc.csv\"\n",
    "qm.to_csv(qm_out_csv, index=True, encoding=\"utf-8-sig\")\n",
    "pd.Series(qc_unit_ids, name=\"unit_id\").to_csv(qc_list_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved:\", qm_out_csv, \"and\", qc_list_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7a6bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[subset] props on an_qc: ['original_cluster_id', 'Amplitude', 'ContamPct', 'KSLabel', 'KSLabel_repeat']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a224fda0094bbdba7c313d3336bfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd84c18b8564f34b1a6e815abd50aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract PCs (workers: 8 processes):   0%|          | 0/5690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  E:\\testephys\\phy_qcpass_clusters\\params.py\n",
      "Exported to Phy -> E:\\testephys\\phy_qcpass_clusters\n"
     ]
    }
   ],
   "source": [
    "#export_to_phy\n",
    "an_qc = an.select_units(unit_ids=qc_unit_ids)\n",
    "sorting_dedup.copy_metadata(an_qc.sorting, ids=an_qc.sorting.unit_ids)\n",
    "normalize_str_props(an_qc.sorting, keys=(\"group\",\"KSLabel\",\"quality\"))\n",
    "props_for_export = [p for p in (\"group\",\"KSLabel\",\"quality\") if p in an_qc.sorting.get_property_keys()]\n",
    "print(\"[subset] props on an_qc:\", an_qc.sorting.get_property_keys())\n",
    "PHY_DIR = Path(r\"E:/testephys/phy_qcpass_clusters\")\n",
    "export_to_phy(\n",
    "    sorting_analyzer=an_qc,\n",
    "    output_folder=PHY_DIR,\n",
    "    remove_if_exists=True,\n",
    "    copy_binary=True, \n",
    "    additional_properties=props_for_export,\n",
    ")\n",
    "print(\"Exported to Phy ->\", PHY_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e990f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeinterface_gui.backend_qt.QtMainWindow(0x2b0d3559ca0) at 0x000002AB651F8380>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GUI curation\n",
    "from spikeinterface_gui import run_mainwindow\n",
    "an_good_mem = an.select_units(unit_ids=qc_unit_ids)  \n",
    "run_mainwindow(an_good_mem, mode=\"desktop\", curation=True)  # mode=\"web/desktop\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1583923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if u want to load data without recomputing\n",
    "# OUT = Path(r\"E:/testephys/postprocessing2.zarr\")  \n",
    "# an = si.load_sorting_analyzer(OUT)            \n",
    "# print(\"已加载扩展：\", an.get_loaded_extension_names())\n",
    "\n",
    "# run_mainwindow(an, mode=\"desktop\", curation=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
